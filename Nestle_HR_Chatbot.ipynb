{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b1e792-81a4-49ce-afb5-07a8de21deb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FAISS index loaded from local storage.\n",
      "‚ö° FAISS Index Size: 35\n",
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Querying FAISS: summarize\n",
      "‚úÖ Retrieved Context: inspired by sound judgement, compliance with \n",
      "local market laws and common sense, taking into \n",
      "account the specific context. Its spirit should be \n",
      "respected under all circumstances and could be \n",
      "summarised in one sentence: At Nestl√© we put \n",
      "people at the centre of everything we do.\n",
      "Jean-Marc Duvoisin\n",
      "Deputy Executive Vice President\n",
      " Introduction HR has adopted a streamlined approach to \n",
      "ensuring functional leadership and the highest \n",
      "level of focus, clarity, and efficiency. Our structure \n",
      "is bas\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "import traceback\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ‚úÖ Step 1: Set Up OpenAI API Key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")  # Read from environment\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"‚ùå ERROR: OpenAI API Key not found. Please set it in environment variables.\")\n",
    "\n",
    "# ‚úÖ Step 2: Load and Process Nestl√© HR Policy PDF\n",
    "pdf_path = \"nestle_hr_policy.pdf\"\n",
    "if not os.path.exists(pdf_path):\n",
    "    raise FileNotFoundError(f\"‚ùå ERROR: PDF file '{pdf_path}' not found in the directory.\")\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# ‚úÖ Step 3: Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "doc_chunks = text_splitter.split_documents(documents)\n",
    "chunk_texts = [chunk.page_content for chunk in doc_chunks]\n",
    "\n",
    "# ‚úÖ Step 4: Initialize OpenAI embeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# ‚úÖ Step 5: Create or Load FAISS Index\n",
    "faiss_path = \"faiss_index\"\n",
    "if os.path.exists(faiss_path):\n",
    "    vectorstore = FAISS.load_local(faiss_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"‚úÖ FAISS index loaded from local storage.\")\n",
    "else:\n",
    "    vectorstore = FAISS.from_texts(chunk_texts, embeddings)\n",
    "    vectorstore.save_local(faiss_path)\n",
    "    print(\"‚úÖ FAISS index created and saved locally.\")\n",
    "\n",
    "# ‚úÖ Debugging: Ensure FAISS has vectors\n",
    "print(f\"‚ö° FAISS Index Size: {vectorstore.index.ntotal}\")  # Should be > 0\n",
    "\n",
    "# ‚úÖ Step 6: Function to Retrieve Answers\n",
    "def get_answer(query):\n",
    "    try:\n",
    "        print(f\"üîπ Querying FAISS: {query}\")\n",
    "\n",
    "        if vectorstore.index.ntotal == 0:\n",
    "            return \"‚ùå Error: No documents found in FAISS. Please add documents first.\"\n",
    "\n",
    "        query_embedding = embeddings.embed_query(query)\n",
    "        docs = vectorstore.similarity_search_by_vector(query_embedding, k=5)\n",
    "\n",
    "        if not docs:\n",
    "            return \"‚ùå Error: No relevant documents found in FAISS.\"\n",
    "\n",
    "        doc_texts = \" \".join([doc.page_content for doc in docs])\n",
    "        if not doc_texts.strip():\n",
    "            return \"‚ùå Error: Retrieved document is empty. Please check FAISS data.\"\n",
    "\n",
    "        print(f\"‚úÖ Retrieved Context: {doc_texts[:500]}\")  # Print first 500 characters\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant for Nestl√© HR policies.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {doc_texts}\\n\\nQuestion: {query}\"}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content  # ‚úÖ Correct access method\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"‚ùå Error: {str(e)}\\n{traceback.format_exc()}\"\n",
    "        print(error_message)\n",
    "        return error_message\n",
    "\n",
    "# ‚úÖ Step 7: Gradio Interface with Error Handling\n",
    "def chatbot(query):\n",
    "    try:\n",
    "        return get_answer(query)\n",
    "    except Exception as e:\n",
    "        error_message = f\"‚ùå Error: {str(e)}\\n{traceback.format_exc()}\"\n",
    "        print(error_message)\n",
    "        return error_message\n",
    "\n",
    "# ‚úÖ Step 8: Launch Gradio UI\n",
    "iface = gr.Interface(fn=chatbot, inputs=\"text\", outputs=\"text\", title=\"Nestl√© HR Assistant\")\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a954c1-ee65-4b88-a80d-06e7196fb3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
